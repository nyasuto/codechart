# C/C++レガシーコード解析パイプライン 開発計画書

## 1. プロジェクトスコープと目標

### 1.1 プロジェクト概要
大規模C/C++レガシーコードベース（最大5万行規模）を効率的に解析し、理解を促進するための自動化パイプラインを開発する。

### 1.2 ビジネス目標
- レガシーコードの保守・リファクタリング工数を30%削減
- 新規参加者のコード理解期間を50%短縮
- コード品質の可視化による技術的負債の定量化

### 1.3 技術目標
- 5万行規模のC/C++コードを24時間以内に完全解析
- GPT-4 APIのトークン制限内で効率的な分割処理
- 90%以上の解析精度達成
- RAGによる類似コード検索精度80%以上

### 1.4 スコープ内
- C/C++ソースコード（.c, .cpp, .h, .hpp）の静的解析
- GPT-4による意味解析とドキュメント生成
- RAGベースの類似コード検索
- 解析結果のJSON/Markdown形式出力
- CLI/Python APIの提供

### 1.5 スコープ外（将来検討）
- リアルタイム解析
- コード自動修正機能
- マルチプロジェクト横断検索
- Web UIの提供
- 他言語（Java, Go等）への対応

---

## 2. 技術選定の詳細と根拠

### 2.1 言語・フレームワーク

#### Python 3.10+
**選定理由:**
- AST解析ライブラリ（pycparser, clang）の充実
- LLM APIクライアントライブラリの豊富さ
- データ処理・機械学習エコシステムの成熟度
- 開発速度とメンテナンス性のバランス

**代替案との比較:**
| 項目 | Python | Go | Rust |
|------|--------|-----|------|
| 開発速度 | ◎ | ○ | △ |
| エコシステム | ◎ | ○ | △ |
| 実行速度 | △ | ◎ | ◎ |
| メンテナンス | ◎ | ○ | △ |

**判断:** 初期開発速度とライブラリの豊富さを優先

### 2.2 C/C++ AST解析

#### pycparser + libclang（ハイブリッド採用）
**選定理由:**
- **pycparser**: 純Python実装、C言語の解析に特化、依存関係が少ない
- **libclang**: C++完全対応、複雑な構文解析に強い、プリプロセッサ対応

**使い分け:**
- Phase 1（cJSON等の純C）: pycparser
- Phase 2以降（C++混在）: libclang

**代替案:**
- clang-format: 整形ツールで解析には不適
- ctags: シンボル抽出のみで構文解析不可

### 2.3 LLM API

#### GPT-4 Turbo (gpt-4-turbo-preview)
**選定理由:**
- 128K トークンコンテキスト（余裕を持って2万トークン使用）
- コード理解能力の高さ
- 自社APIインフラ対応

**制約条件:**
- エージェント機能不使用（自社API制限）
- レート制限: 10,000 TPM (tokens per minute)
- コスト: $0.01/1K入力トークン、$0.03/1K出力トークン

**コスト試算（5万行解析）:**
```
入力: 50,000行 × 平均30トークン/行 = 1,500K トークン
     1,500K × $0.01/1K = $15
出力: 推定300K トークン（要約・解説）
     300K × $0.03/1K = $9
合計: 約$24/回（全体解析）
```

### 2.4 ベクトルデータベース

#### ChromaDB（Phase 1採用）
**選定理由:**
- セットアップ不要（SQLiteベース）
- Python APIのシンプルさ
- OpenAI Embeddingsとの相性

**Phase 2以降の検討:**
- **FAISS**: 大規模データ（10万ベクトル以上）で高速
- **Weaviate**: 分散環境・本番運用向け

| 項目 | ChromaDB | FAISS | Weaviate |
|------|----------|-------|----------|
| セットアップ | ◎ | ○ | △ |
| 小規模性能 | ◎ | ○ | ○ |
| 大規模性能 | ○ | ◎ | ◎ |
| クラウド対応 | △ | △ | ◎ |

### 2.5 テスト・品質管理

- **テストフレームワーク**: pytest
- **カバレッジ**: pytest-cov（目標80%以上）
- **リンター**: ruff
- **フォーマッター**: ruff format
- **型チェック**: mypy
- **CI/CD**: GitHub Actions

---

## 3. フェーズ別開発計画

### Phase 1: 基本パイプライン構築（Week 1-2）
**目標:** cJSON（8,000行）で動作するMVP完成

#### マイルストーン 1.1: 環境構築（Day 1-2）
- [ ] プロジェクト構造作成
- [ ] Poetry/requirements.txt設定
- [ ] CI/CD基本設定（GitHub Actions）
- [ ] 開発環境Docker化（オプション）

#### マイルストーン 1.2: コア機能実装（Day 3-7）
- [ ] コード分割モジュール（`src/code_chunker.py`）
  - 関数単位での分割
  - トークン数計算（tiktoken）
  - 2万トークン以下のチャンク生成
- [ ] LLM解析モジュール（`src/llm_analyzer.py`）
  - GPT-4 API クライアント
  - プロンプトテンプレート管理
  - エラーハンドリング・リトライ機能
- [ ] 結果出力モジュール（`src/output_formatter.py`）
  - JSON形式出力
  - Markdown形式レポート生成

#### マイルストーン 1.3: 初期検証（Day 8-10）
- [ ] cJSONでの動作確認
- [ ] 単体テスト作成（カバレッジ60%以上）
- [ ] 性能計測（処理時間・トークン消費）
- [ ] ドキュメント初版（README更新）

**成果物:**
- 動作するMVPパイプライン
- cJSON解析結果サンプル
- 性能レポート（処理時間・コスト）

---

### Phase 2: 静的解析統合（Week 3-4）
**目標:** 3万行規模への拡張と静的解析ツール統合

#### マイルストーン 2.1: 静的解析連携（Day 11-14）
- [ ] Cppcheck統合（バグ検出）
- [ ] ctags統合（シンボルインデックス）
- [ ] 複雑度計算（Cyclomatic Complexity）
- [ ] 解析結果のマージ処理

#### マイルストーン 2.2: スケーラビリティ向上（Day 15-17）
- [ ] 並列処理実装（multiprocessing）
- [ ] 増分解析機能（差分のみ処理）
- [ ] キャッシュ機構（解析済みチャンク）

#### マイルストーン 2.3: Phase 2検証（Day 18-20）
- [ ] miniz（10,000行）での検証
- [ ] mongoose部分（15,000行）での検証
- [ ] 統合テスト追加（カバレッジ70%以上）

**成果物:**
- 静的解析統合パイプライン
- 3万行規模対応確認
- 性能改善レポート

---

### Phase 3: RAGシステム構築（Week 5-6）
**目標:** 類似コード検索とナレッジベース構築

#### マイルストーン 3.1: ベクトルDB統合（Day 21-24）
- [ ] ChromaDB統合
- [ ] OpenAI Embeddings API連携
- [ ] コードチャンクのベクトル化
- [ ] 類似度検索API実装

#### マイルストーン 3.2: RAG機能実装（Day 25-27）
- [ ] 関連コード自動検索
- [ ] コンテキスト拡張機能
- [ ] 検索結果ランキング

#### マイルストーン 3.3: Phase 3検証（Day 28-30）
- [ ] 検索精度評価（テストセット作成）
- [ ] E2Eテスト（カバレッジ80%以上）
- [ ] ユーザードキュメント整備

**成果物:**
- RAG対応パイプライン
- 類似コード検索機能
- 精度評価レポート

---

### Phase 4: 本番運用準備（Week 7-8）
**目標:** 5万行規模対応とプロダクション品質確保

#### マイルストーン 4.1: 大規模対応（Day 31-34）
- [ ] Redis（5万行）での検証
- [ ] メモリ最適化
- [ ] エラーハンドリング強化
- [ ] ログ・モニタリング実装

#### マイルストーン 4.2: 性能最適化（Day 35-38）
- [ ] ボトルネック解析
- [ ] クエリ最適化
- [ ] バッチ処理改善

#### マイルストーン 4.3: リリース準備（Day 39-42）
- [ ] セキュリティ監査
- [ ] APIドキュメント完成
- [ ] 運用マニュアル作成
- [ ] v1.0.0リリース

**成果物:**
- プロダクション品質パイプライン
- 完全なドキュメント
- 運用手順書

---

## 4. リスク評価と対策

### 4.1 技術リスク

#### リスク T-1: GPT-4 APIレート制限超過
**影響度:** 高
**発生確率:** 中
**対策:**
- 指数バックオフリトライ実装
- チャンクサイズ動的調整
- 代替API（Claude等）の検討
- オフピーク時間の利用

#### リスク T-2: C++複雑構文の解析失敗
**影響度:** 中
**発生確率:** 高
**対策:**
- pycparser/libclangのハイブリッド利用
- プリプロセス済みコードへのフォールバック
- 解析失敗箇所のマニュアルレビュー機能
- エラーログの詳細記録

#### リスク T-3: メモリ不足（大規模コード処理）
**影響度:** 中
**発生確率:** 中
**対策:**
- ストリーミング処理の採用
- チャンクサイズ制限
- ディスクスワップの活用
- 分散処理への移行（Phase 4）

### 4.2 プロジェクトリスク

#### リスク P-1: スケジュール遅延
**影響度:** 中
**発生確率:** 中
**対策:**
- 週次進捗レビュー
- マイルストーンごとのバッファ（2日）
- スコープ調整の柔軟性確保

#### リスク P-2: コスト超過（API料金）
**影響度:** 低
**発生確率:** 低
**対策:**
- 日次コストモニタリング
- トークン数上限設定
- キャッシュ活用によるAPI呼び出し削減

---

## 5. 成功指標の定義

### 5.1 機能要件指標

| 指標 | 目標値 | 測定方法 |
|------|--------|----------|
| コード解析カバレッジ | 95%以上 | 解析成功行数 / 総行数 |
| 処理速度 | 5万行を24時間以内 | E2Eベンチマーク |
| RAG検索精度 | 80%以上（Top-5） | テストクエリセット評価 |
| エラー率 | 5%以下 | 失敗チャンク数 / 総チャンク数 |

### 5.2 品質指標

| 指標 | 目標値 | 測定方法 |
|------|--------|----------|
| テストカバレッジ | 80%以上 | pytest-cov |
| 型チェック合格率 | 100% | mypy strict mode |
| リンターエラー | 0件 | ruff check |
| セキュリティ脆弱性 | Critical 0件 | bandit, safety |

### 5.3 ビジネス指標（Phase 4以降）

| 指標 | 目標値 | 測定期間 |
|------|--------|----------|
| コード理解時間短縮 | 50%削減 | 3ヶ月 |
| 保守工数削減 | 30%削減 | 6ヶ月 |
| ユーザー満足度 | 4.0/5.0以上 | リリース後1ヶ月 |

### 5.4 コスト指標

| 項目 | 予算 | 実績管理 |
|------|------|----------|
| 開発工数 | 8週（1名） | 週次レポート |
| GPT-4 API費用 | $500/月 | 日次ログ |
| インフラ費用 | $100/月 | 月次請求 |

---

## 6. 次のアクション

### 即時タスク（今週）
1. ✅ プロジェクト構造作成
2. ⏳ Issue #1-5 作成
3. ⏳ 技術調査タスク開始
4. ⏳ CI/CD環境構築

### Week 1の目標
- 環境構築完了
- コア機能実装開始
- cJSON準備

---

## 改訂履歴
| 日付 | バージョン | 変更内容 | 作成者 |
|------|------------|----------|--------|
| 2025-11-02 | 1.0 | 初版作成 | - |
